{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19_스팸메일분류_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleRNN을 이용한 SMS Spam 분류\n",
        "    캐글 데이터: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
        "    \"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/spam.csv\" "
      ],
      "metadata": {
        "id": "Qf6AXBGym0hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "download_url = 'https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/spam.csv'\n",
        "df = pd.read_csv(download_url, encoding='latin1')\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "RTTdLqYwFHBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리"
      ],
      "metadata": {
        "id": "Hum2kbdJnpZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selection\n",
        "df = df[['v1','v2']]    # df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'], inplace=True)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "G4_V8zswnmiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null 데이터 확인\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "tjg1X5RtrDNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 데이터 확인\n",
        "df.shape, df.v2.nunique()"
      ],
      "metadata": {
        "id": "ZaHwy5Y4rXss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['v2'], inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "q6JgUGbbrjMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ['ham', 'spam'] --> [0, 1] 로 변경\n",
        "df.v1 = df.v1.replace(['ham','spam'], [0,1])\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "kn5Z_mmar1xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ham/Spam 갯수\n",
        "df.v1.value_counts()"
      ],
      "metadata": {
        "id": "voymTmcDsKy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x, y data\n",
        "x = df.v2.values\n",
        "y = df.v1.values\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "3emvXRqyszJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 전처리"
      ],
      "metadata": {
        "id": "ph7_r6NltH3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "kORPR3PxtFRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구둣점 제거, 소문자 변환\n",
        "import re\n",
        "\n",
        "def preprocessing(s):\n",
        "    s = s.encode('utf8').decode('ascii','ignore')   # 파이썬에서 문자열은 유니코드로 처리\n",
        "    s = re.sub('[^a-z0-9 ]', '', s.lower())\n",
        "    return s"
      ],
      "metadata": {
        "id": "XRF3bpAftblb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = [preprocessing(sent) for sent in x]\n",
        "X_data[2]"
      ],
      "metadata": {
        "id": "3B0H9H6puQiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합을 만들고, 그 크기를 확인\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_data)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "id": "qg__F8DJvGbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = t.texts_to_sequences(X_data)\n",
        "print(sequences[2])"
      ],
      "metadata": {
        "id": "9YJVskg-wBLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(seq) for seq in sequences)\n",
        "max_len"
      ],
      "metadata": {
        "id": "iBXDfvHUw1YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터셋의 길이를 max_len에 맞추고, 0 padding을 해줌.\n",
        "data = pad_sequences(sequences, maxlen=max_len)"
      ],
      "metadata": {
        "id": "RMVMW5U3xEIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train/test dataset 분리"
      ],
      "metadata": {
        "id": "CA_akTRN1vp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "1e2IdAXe1Wqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, y, stratify=y, test_size=0.2, random_state=seed\n",
        ")\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "nRQNoWPByOni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 정의/설정/학습"
      ],
      "metadata": {
        "id": "yff49VlS1ZiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "ptedXbTP117X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([ \n",
        "    Embedding(vocab_size, 32, input_length=max_len),\n",
        "    SimpleRNN(32, activation='tanh'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hZk4wjma2LkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam', 'binary_crossentropy', ['accuracy'])"
      ],
      "metadata": {
        "id": "lqSgg9RM2p2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'best-spam.h5'\n",
        "checkpoint = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
        "early_stop = EarlyStopping(patience=10)"
      ],
      "metadata": {
        "id": "9lEd48JL3jj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train, epochs=100, batch_size=64,\n",
        "                 validation_split=0.2, callbacks=[checkpoint, early_stop])"
      ],
      "metadata": {
        "id": "Da_-Mf2B4Dvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "5oVzSzBW4V2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련과정 시각화"
      ],
      "metadata": {
        "id": "KHK0dY9b5BGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_acc = hist.history['accuracy']\n",
        "y_vloss = hist.history['val_loss']\n",
        "xs = np.arange(1, len(y_acc)+1)"
      ],
      "metadata": {
        "id": "sRK-RX9_47xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(xs, y_acc, label='train accuracy')\n",
        "plt.plot(xs, y_vloss, label='validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid(), plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Drez7Tsv5RfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bAiVRYil5zVF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}