{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGD(Stochastic Gradient Descent): 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(x,y) = x*x + y*y + xy - 4x - 8y\n",
    "def func(params):\n",
    "    x, y = params['x'], params['y']\n",
    "    return x*x + y*y + x*y - 4.*x - 8.*y\n",
    "\n",
    "# Df(x,y) = (2x + y - 4, 2y + x - 8)\n",
    "def deriv_f(params):\n",
    "    x, y = params['x'], params['y']\n",
    "    return {'x': round(2*x + y - 4., 4), 'y': round(2*y + x - 8., 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기값: params={'x': 0.0, 'y': 0.0}, grads={'x': -4.0, 'y': -8.0}, func=0.0000\n",
      "1회 시행: params={'x': 2.0, 'y': 4.0}, grads={'x': -4.0, 'y': -8.0}, func=-12.0000\n",
      "2회 시행: params={'x': 0.0, 'y': 3.0}, grads={'x': 4.0, 'y': 2.0}, func=-15.0000\n",
      "3회 시행: params={'x': 0.5, 'y': 4.0}, grads={'x': -1.0, 'y': -2.0}, func=-15.7500\n",
      "4회 시행: params={'x': 0.0, 'y': 3.75}, grads={'x': 1.0, 'y': 0.5}, func=-15.9375\n",
      "5회 시행: params={'x': 0.125, 'y': 4.0}, grads={'x': -0.25, 'y': -0.5}, func=-15.9844\n",
      "6회 시행: params={'x': 0.0, 'y': 3.9375}, grads={'x': 0.25, 'y': 0.125}, func=-15.9961\n",
      "7회 시행: params={'x': 0.03125, 'y': 4.0}, grads={'x': -0.0625, 'y': -0.125}, func=-15.9990\n",
      "8회 시행: params={'x': 0.0, 'y': 3.9844}, grads={'x': 0.0625, 'y': 0.0312}, func=-15.9998\n",
      "9회 시행: params={'x': 0.0078, 'y': 4.0}, grads={'x': -0.0156, 'y': -0.0312}, func=-15.9999\n",
      "10회 시행: params={'x': 0.0, 'y': 3.9961}, grads={'x': 0.0156, 'y': 0.0078}, func=-16.0000\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(0.5)\n",
    "params = {'x':0., 'y':0.}\n",
    "grads = deriv_f(params)\n",
    "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "for i in range(10):\n",
    "    sgd.update(params, grads)\n",
    "    print(f'{i+1}회 시행: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "    grads = deriv_f(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Momentum\n",
    "    - Gradient Descent에 현재의 관성을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기값: params={'x': 0.0, 'y': 0.0}, grads={'x': -4.0, 'y': -8.0}, func=0.0000\n",
      "1회 시행: params={'x': 2.0, 'y': 4.0}, grads={'x': -4.0, 'y': -8.0}, v={'x': 2.0, 'y': 4.0}, func=-12.0000\n",
      "2회 시행: params={'x': 1.0, 'y': 5.0}, grads={'x': 4.0, 'y': 2.0}, v={'x': -1.0, 'y': 1.0}, func=-13.0000\n",
      "3회 시행: params={'x': -1.0, 'y': 4.0}, grads={'x': 3.0, 'y': 3.0}, v={'x': -2.0, 'y': -1.0}, func=-15.0000\n",
      "4회 시행: params={'x': -1.0, 'y': 4.0}, grads={'x': -2.0, 'y': -1.0}, v={'x': 0.0, 'y': 0.0}, func=-15.0000\n",
      "5회 시행: params={'x': 0.0, 'y': 4.5}, grads={'x': -2.0, 'y': -1.0}, v={'x': 1.0, 'y': 0.5}, func=-15.7500\n",
      "6회 시행: params={'x': 0.25, 'y': 4.25}, grads={'x': 0.5, 'y': 1.0}, v={'x': 0.25, 'y': -0.25}, func=-15.8125\n",
      "7회 시행: params={'x': 0.0, 'y': 3.75}, grads={'x': 0.75, 'y': 0.75}, v={'x': -0.25, 'y': -0.5}, func=-15.9375\n",
      "8회 시행: params={'x': 0.0, 'y': 3.75}, grads={'x': -0.25, 'y': -0.5}, v={'x': 0.0, 'y': 0.0}, func=-15.9375\n",
      "9회 시행: params={'x': 0.125, 'y': 4.0}, grads={'x': -0.25, 'y': -0.5}, v={'x': 0.125, 'y': 0.25}, func=-15.9844\n",
      "10회 시행: params={'x': 0.0625, 'y': 4.0625}, grads={'x': 0.25, 'y': 0.125}, v={'x': -0.0625, 'y': 0.0625}, func=-15.9883\n"
     ]
    }
   ],
   "source": [
    "momentum = Momentum(lr=0.5, momentum=0.5)\n",
    "params = {'x':0., 'y':0.}\n",
    "grads = deriv_f(params)\n",
    "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "for i in range(10):\n",
    "    momentum.update(params, grads)\n",
    "    print(f'{i+1}회 시행: params={params}, grads={grads}, v={momentum.v}, func={func(params):.4f}')\n",
    "    grads = deriv_f(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NAG(Nesterov Accelerated Gradient)\n",
    "    * 현재 위치에서의 관성과 관성방향으로 움직인 후 위치에서의 gradient 반대방향을 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nesterov:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "        for key in params.keys():\n",
    "            params[key] += self.momentum * self.momentum * self.v[key]\n",
    "            params[key] -= (1 + self.momentum) * self.lr * grads[key]\n",
    "            self.v[key] *= self.momentum\n",
    "            self.v[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기값: params={'x': 0.0, 'y': 0.0}, grads={'x': -4.0, 'y': -8.0}, func=0.0000\n",
      "1회 시행: params={'x': 1.4400000000000002, 'y': 2.8800000000000003}, grads={'x': -4.0, 'y': -8.0}, v={'x': -0.0625, 'y': 0.0625}, func=-14.2848\n",
      "2회 시행: params={'x': 1.3184000000000005, 'y': 4.192000000000001}, grads={'x': 1.76, 'y': -0.8}, v={'x': -0.0625, 'y': 0.0625}, func=-13.9718\n",
      "3회 시행: params={'x': 0.48435200000000034, 'y': 4.500736000000002}, grads={'x': 2.8288, 'y': 1.7024}, v={'x': -0.0625, 'y': 0.0625}, func=-15.2721\n",
      "4회 시행: params={'x': -0.2592623999999998, 'y': 4.485220800000002}, grads={'x': 1.4694, 'y': 1.4858}, v={'x': -0.0625, 'y': 0.0625}, func=-15.8231\n",
      "5회 시행: params={'x': -0.6070619199999999, 'y': 4.454504640000002}, grads={'x': -0.0333, 'y': 0.7112}, v={'x': -0.0625, 'y': 0.0625}, func=-15.7008\n",
      "6회 시행: params={'x': -0.617173536, 'y': 4.435039712000003}, grads={'x': -0.7596, 'y': 0.3019}, v={'x': -0.0625, 'y': 0.0625}, func=-15.6983\n",
      "7회 시행: params={'x': -0.4590508288, 'y': 4.376727769600003}, grads={'x': -0.7993, 'y': 0.2529}, v={'x': -0.0625, 'y': 0.0625}, func=-15.8203\n",
      "8회 시행: params={'x': -0.26553666303999995, 'y': 4.264558215680003}, grads={'x': -0.5414, 'y': 0.2944}, v={'x': -0.0625, 'y': 0.0625}, func=-15.9297\n",
      "9회 시행: params={'x': -0.10140933043199994, 'y': 4.127030572544003}, grads={'x': -0.2665, 'y': 0.2636}, v={'x': -0.0625, 'y': 0.0625}, func=-15.9865\n",
      "10회 시행: params={'x': 0.014540535654400083, 'y': 4.0042124580352025}, grads={'x': -0.0758, 'y': 0.1527}, v={'x': -0.0625, 'y': 0.0625}, func=-15.9997\n"
     ]
    }
   ],
   "source": [
    "nesterov = Nesterov(lr=0.2, momentum=0.8)\n",
    "params = {'x':0., 'y':0.}\n",
    "grads = deriv_f(params)\n",
    "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "for i in range(10):\n",
    "    nesterov.update(params, grads)\n",
    "    print(f'{i+1}회 시행: params={params}, grads={grads}, v={momentum.v}, func={func(params):.4f}')\n",
    "    grads = deriv_f(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AdaGrad\n",
    "    - 일정한 learning rate를 사용하지 않고 변수마다 그리고 스텝마다 learning rate가 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key in params.keys():\n",
    "                self.h[key] = 0.\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.h[key] = round(self.h[key] + grads[key] * grads[key], 4)\n",
    "            params[key] = round(params[key] - self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기값: params={'x': 0.0, 'y': 0.0}, grads={'x': -4.0, 'y': -8.0}, func=0.0000\n",
      "1회 시행: params={'x': 10.0, 'y': 10.0}, grads={'x': -4.0, 'y': -8.0}, h={'x': 16.0, 'y': 64.0}, func=180.0000\n",
      "2회 시행: params={'x': 0.1163, 'y': 0.6021}, grads={'x': 26.0, 'y': 22.0}, h={'x': 692.0, 'y': 548.0}, func=-4.8359\n",
      "3회 시행: params={'x': 1.3109, 'y': 3.3459}, grads={'x': -3.1653, 'y': -6.6795}, h={'x': 702.0191, 'y': 592.6157}, func=-14.7112\n",
      "4회 시행: params={'x': 0.5703, 'y': 3.3448}, grads={'x': 1.9677, 'y': 0.0027}, h={'x': 705.8909, 'y': 592.6157}, func=-15.6191\n",
      "5회 시행: params={'x': 0.3876, 'y': 3.6487}, grads={'x': 0.4854, 'y': -0.7401}, h={'x': 706.1265, 'y': 593.1634}, func=-15.8625\n",
      "6회 시행: params={'x': 0.2281, 'y': 3.778}, grads={'x': 0.4239, 'y': -0.315}, h={'x': 706.3062, 'y': 593.2626}, func=-15.9493\n",
      "7회 시행: params={'x': 0.14, 'y': 3.8666}, grads={'x': 0.2342, 'y': -0.2159}, h={'x': 706.361, 'y': 593.3092}, func=-15.9813\n",
      "8회 시행: params={'x': 0.0848, 'y': 3.9187}, grads={'x': 0.1466, 'y': -0.1268}, h={'x': 706.3825, 'y': 593.3253}, func=-15.9931\n",
      "9회 시행: params={'x': 0.0516, 'y': 3.9506}, grads={'x': 0.0883, 'y': -0.0778}, h={'x': 706.3903, 'y': 593.3314}, func=-15.9974\n",
      "10회 시행: params={'x': 0.0314, 'y': 3.97}, grads={'x': 0.0538, 'y': -0.0472}, h={'x': 706.3932, 'y': 593.3336}, func=-15.9991\n"
     ]
    }
   ],
   "source": [
    "adg = AdaGrad(lr=10)\n",
    "params = {'x':0., 'y':0.}\n",
    "grads = deriv_f(params)\n",
    "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "for i in range(10):\n",
    "    adg.update(params, grads)\n",
    "    print(f'{i+1}회 시행: params={params}, grads={grads}, h={adg.h}, func={func(params):.4f}')\n",
    "    grads = deriv_f(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSProp\n",
    "    - AdaGrad는 스텝이 많이 진행되면 h 값이 너무 커져서 학습률이 너무 작아져 학습이 거의 되지 않음\n",
    "    - 이를 보완하기 위해 이전 누적치와 현재 그래디언트의 좌표별 제곱의 가중치 평균을 반영함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSProp:\n",
    "    def __init__(self, lr=0.01, gamma=0.75):    # gamma: forgetting factor(decay rate)\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma      # gamma가 클수록 과거가 중요하고, 작을수록 현재(gradient)가 중요\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key in params.keys():\n",
    "                self.h[key] = 0.\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.h[key] = round(self.gamma * self.h[key] + (1 - self.gamma) * grads[key] * grads[key], 4)\n",
    "            params[key] = round(params[key] - self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기값: params={'x': 0.0, 'y': 0.0}, grads={'x': -4.0, 'y': -8.0}, func=0.0000\n",
      "1회 시행: params={'x': 1.8, 'y': 1.8}, grads={'x': -4.0, 'y': -8.0}, h={'x': 4.0, 'y': 16.0}, func=-11.8800\n",
      "2회 시행: params={'x': 1.1255, 'y': 2.4324}, grads={'x': 1.4, 'y': -2.6}, h={'x': 3.49, 'y': 13.69}, func=-14.0402\n",
      "3회 시행: params={'x': 0.7535, 'y': 2.971}, grads={'x': 0.6834, 'y': -2.0097}, h={'x': 2.7343, 'y': 11.2772}, func=-15.1487\n",
      "4회 시행: params={'x': 0.4572, 'y': 3.3649}, grads={'x': 0.478, 'y': -1.3045}, h={'x': 2.1078, 'y': 8.8833}, func=-15.6780\n",
      "5회 시행: params={'x': 0.2585, 'y': 3.6449}, grads={'x': 0.2793, 'y': -0.813}, h={'x': 1.6004, 'y': 6.8277}, func=-15.8989\n",
      "6회 시행: params={'x': 0.1259, 'y': 3.8237}, grads={'x': 0.1619, 'y': -0.4517}, h={'x': 1.2069, 'y': 5.1718}, func=-15.9753\n",
      "7회 시행: params={'x': 0.0545, 'y': 3.9271}, grads={'x': 0.0755, 'y': -0.2267}, h={'x': 0.9066, 'y': 3.8917}, func=-15.9957\n",
      "8회 시행: params={'x': 0.0151, 'y': 3.9752}, grads={'x': 0.0361, 'y': -0.0913}, h={'x': 0.6803, 'y': 2.9209}, func=-15.9995\n",
      "9회 시행: params={'x': 0.0083, 'y': 3.9962}, grads={'x': 0.0054, 'y': -0.0345}, h={'x': 0.5102, 'y': 2.191}, func=-15.9999\n",
      "10회 시행: params={'x': -0.0103, 'y': 3.9957}, grads={'x': 0.0128, 'y': 0.0007}, h={'x': 0.3827, 'y': 1.6433}, func=-15.9998\n"
     ]
    }
   ],
   "source": [
    "rmsp = RMSProp(lr=0.9, gamma=0.75)\n",
    "params = {'x':0., 'y':0.}\n",
    "grads = deriv_f(params)\n",
    "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "for i in range(10):\n",
    "    rmsp.update(params, grads)\n",
    "    print(f'{i+1}회 시행: params={params}, grads={grads}, h={rmsp.h}, func={func(params):.4f}')\n",
    "    grads = deriv_f(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adam\n",
    "    - Momentum과 RMSProp 두가지 방식을 혼합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr, self.beta1, self.beta2 = lr, beta1, beta2\n",
    "        self.iter, self.m, self.v = 0, None, None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key in params.keys():\n",
    "                self.m[key], self.v[key] = 0., 0.\n",
    "                \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1. - self.beta2**self.iter) / (1. - self.beta1**self.iter)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.m[key] = round(self.beta1 * self.m[key] + (1. - self.beta1) * grads[key], 4)\n",
    "            # self.m[key] += (1. - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] = round(self.beta2 * self.v[key] + (1. - self.beta2) * grads[key]**2, 4)\n",
    "            # self.v[key] += (1. - self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            params[key] = round(params[key] - lr_t * self.m[key] / (np.sqrt(self.v[key] + 1e-7)), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기값: params={'x': 0.0, 'y': 0.0}, grads={'x': -4.0, 'y': -8.0}, func=0.0000\n",
      "1회 시행: params={'x': 0.9, 'y': 0.9}, grads={'x': -4.0, 'y': -8.0}, m={'x': -0.4, 'y': -0.8}, v={'x': 0.016, 'y': 0.064}, func=-8.3700\n",
      "2회 시행: params={'x': 1.68, 'y': 1.7728}, grads={'x': -1.3, 'y': -5.3}, m={'x': -0.49, 'y': -1.25}, v={'x': 0.0177, 'y': 0.092}, func=-11.9589\n",
      "3회 시행: params={'x': 2.1122, 'y': 2.5807}, grads={'x': 1.1328, 'y': -2.7744}, m={'x': -0.3277, 'y': -1.4024}, v={'x': 0.019, 'y': 0.0996}, func=-12.5220\n",
      "4회 시행: params={'x': 2.1267, 'y': 3.2788}, grads={'x': 2.8051, 'y': -0.7264}, m={'x': -0.0144, 'y': -1.3348}, v={'x': 0.0268, 'y': 0.1}, func=-12.4908\n",
      "5회 시행: params={'x': 1.8599, 'y': 3.8339}, grads={'x': 3.5322, 'y': 0.6843}, m={'x': 0.3403, 'y': -1.1329}, v={'x': 0.0392, 'y': 0.1004}, func=-12.8221\n",
      "6회 시행: params={'x': 1.4279, 'y': 4.236}, grads={'x': 3.5537, 'y': 1.5277}, m={'x': 0.6616, 'y': -0.8668}, v={'x': 0.0518, 'y': 0.1026}, func=-13.5684\n",
      "7회 시행: params={'x': 0.9013, 'y': 4.4971}, grads={'x': 3.0918, 'y': 1.8999}, m={'x': 0.9046, 'y': -0.5901}, v={'x': 0.0613, 'y': 0.1061}, func=-14.4925\n",
      "8회 시행: params={'x': 0.33, 'y': 4.6426}, grads={'x': 2.2997, 'y': 1.8955}, m={'x': 1.0441, 'y': -0.3415}, v={'x': 0.0665, 'y': 0.1096}, func=-15.2661\n",
      "9회 시행: params={'x': -0.2404, 'y': 4.7032}, grads={'x': 1.3026, 'y': 1.6152}, m={'x': 1.07, 'y': -0.1458}, v={'x': 0.0681, 'y': 0.1121}, func=-15.6168\n",
      "10회 시행: params={'x': -0.7609, 'y': 4.7092}, grads={'x': 0.2224, 'y': 1.166}, m={'x': 0.9852, 'y': -0.0146}, v={'x': 0.0681, 'y': 0.1133}, func=-15.4577\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.9)\n",
    "params = {'x':0., 'y':0.}\n",
    "grads = deriv_f(params)\n",
    "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
    "for i in range(10):\n",
    "    adam.update(params, grads)\n",
    "    print(f'{i+1}회 시행: params={params}, grads={grads}, m={adam.m}, v={adam.v}, func={func(params):.4f}')\n",
    "    grads = deriv_f(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a1baeb1610b05443f415525bf52a486212d0ee94c2d320214bf0d7d56e225dd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('vsc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
