{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PwaTfKlq-iK"
      },
      "source": [
        "# Unit 10. Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A0Hbyovq-iN"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHpvc4Eq-iO"
      },
      "source": [
        "- 함수 및 도함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ehx1OUKq-iO"
      },
      "outputs": [],
      "source": [
        "# f(x,y) = x*x + y*y + xy - 4x - 8y\n",
        "def func(params):\n",
        "    x, y = params\n",
        "    return x*x + y*y + x*y - 4.*x - 8.*y\n",
        "\n",
        "# Df(x,y) = (2x + y - 4, 2y + x - 8)\n",
        "def deriv_f(params):\n",
        "    x, y = params\n",
        "    return np.array((np.round(2*x + y - 4., 4), np.round(2*y + x - 8., 4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DvCXH5aq-iP"
      },
      "source": [
        "- SGD(Stochastic Gradient Descent): 확률적 경사 하강법"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    def update(self, params, grads):\n",
        "        for i in range(params.shape[0]):\n",
        "            params[i] -= self.lr * grads[i]"
      ],
      "metadata": {
        "id": "jAI8-uLMtZuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Wo1i0mq-iP"
      },
      "outputs": [],
      "source": [
        "sgd = SGD(0.5)\n",
        "params = np.array((0,0), dtype=np.float32)\n",
        "grads = deriv_f(params)\n",
        "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "for i in range(10):\n",
        "    sgd.update(params, grads)\n",
        "    print(f'{i+1}회 시행: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "    grads = deriv_f(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib4vUYQ7q-iQ"
      },
      "source": [
        "- Momentum\n",
        "    - Gradient Descent에 현재의 관성을 추가"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Momentum:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = np.zeros_like(params)\n",
        "        for i in range(len(params)):\n",
        "            self.v[i] = self.momentum * self.v[i] - self.lr * grads[i]\n",
        "            params[i] += self.v[i]"
      ],
      "metadata": {
        "id": "ip-hqWl3t0AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cThhieRbq-iQ"
      },
      "outputs": [],
      "source": [
        "momentum = Momentum(lr=0.5, momentum=0.5)\n",
        "params = np.zeros(2, dtype=np.float32)\n",
        "grads = deriv_f(params)\n",
        "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "for i in range(10):\n",
        "    momentum.update(params, grads)\n",
        "    print(f'{i+1}회 시행: params={params}, grads={grads}, v={momentum.v}, func={func(params):.4f}')\n",
        "    grads = deriv_f(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG9VCjy9q-iR"
      },
      "source": [
        "- NAG(Nesterov Accelerated Gradient)\n",
        "    - 현재 위치에서의 관성과 관성방향으로 움직인 후 위치에서의 gradient 반대방향을 합침"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NAG:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = np.zeros_like(params)\n",
        "        for i in range(len(params)):\n",
        "            params[i] += self.momentum * self.momentum * self.v[i]\n",
        "            params[i] -= (1 + self.momentum) * self.lr * grads[i]\n",
        "            self.v[i] *= self.momentum\n",
        "            self.v[i] -= self.lr * grads[i]"
      ],
      "metadata": {
        "id": "QCVFtKIpuHTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqW-E963q-iR"
      },
      "outputs": [],
      "source": [
        "nag = NAG(lr=0.2, momentum=0.8)\n",
        "params = np.zeros(2, dtype=np.float32)\n",
        "grads = deriv_f(params)\n",
        "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "for i in range(10):\n",
        "    nag.update(params, grads)\n",
        "    print(f'{i+1}회 시행: params={params}, grads={grads}, v={momentum.v}, func={func(params):.4f}')\n",
        "    grads = deriv_f(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ezejPHbq-iR"
      },
      "source": [
        "- AdaGrad\n",
        "    - 일정한 learning rate를 사용하지 않고 변수마다 그리고 스텝마다 learning rate가 바뀜"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = np.zeros_like(params)\n",
        "        for i in range(len(params)):\n",
        "            self.h[i] = round(self.h[i] + grads[i] * grads[i], 4)\n",
        "            params[i] = round(params[i] - self.lr * grads[i] / (np.sqrt(self.h[i]) + 1e-7), 4)"
      ],
      "metadata": {
        "id": "OzJHY-q3uXPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgmqUSkUq-iS"
      },
      "outputs": [],
      "source": [
        "adg = AdaGrad(lr=10)\n",
        "params = np.zeros(2, dtype=np.float32)\n",
        "grads = deriv_f(params)\n",
        "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "for i in range(10):\n",
        "    adg.update(params, grads)\n",
        "    print(f'{i+1}회 시행: params={params}, grads={grads}, h={adg.h}, func={func(params):.4f}')\n",
        "    grads = deriv_f(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N53mRJ5Jq-iS"
      },
      "source": [
        "- RMSProp\n",
        "    - AdaGrad는 스텝이 많이 진행되면 h 값이 너무 커져서 학습률이 너무 작아져 학습이 거의 되지 않음\n",
        "    - 이를 보완하기 위해 이전 누적치와 현재 그래디언트의 좌표별 제곱의 가중치 평균을 반영함"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSProp:\n",
        "    def __init__(self, lr=0.01, gamma=0.75):    # gamma: forgetting factor(decay rate)\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma      # gamma가 클수록 과거가 중요하고, 작을수록 현재(gradient)가 중요\n",
        "        self.h = None\n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = np.zeros_like(params)\n",
        "        for i in range(len(params)):\n",
        "            self.h[i] = round(self.gamma * self.h[i] + (1 - self.gamma) * grads[i] * grads[i], 4)\n",
        "            params[i] = round(params[i] - self.lr * grads[i] / (np.sqrt(self.h[i]) + 1e-7), 4)"
      ],
      "metadata": {
        "id": "XEEPvM2nu9K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7vjIdYcq-iS"
      },
      "outputs": [],
      "source": [
        "rmsp = RMSProp(lr=0.9, gamma=0.75)\n",
        "params = np.zeros(2, dtype=np.float32)\n",
        "grads = deriv_f(params)\n",
        "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "for i in range(10):\n",
        "    rmsp.update(params, grads)\n",
        "    print(f'{i+1}회 시행: params={params}, grads={grads}, h={rmsp.h}, func={func(params):.4f}')\n",
        "    grads = deriv_f(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx4jSHs3q-iT"
      },
      "source": [
        "- Adam\n",
        "    - Momentum과 RMSProp 두가지 방식을 혼합"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam:\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr, self.beta1, self.beta2 = lr, beta1, beta2\n",
        "        self.iter, self.m, self.v = 0, None, None\n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m = np.zeros_like(params)\n",
        "            self.v = np.zeros_like(params)\n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * np.sqrt(1. - self.beta2**self.iter) / (1. - self.beta1**self.iter)\n",
        "        \n",
        "        for i in range(len(params)):\n",
        "            self.m[i] = round(self.beta1 * self.m[i] + (1. - self.beta1) * grads[i], 4)\n",
        "            # self.m[i] += (1. - self.beta1) * (grads[i] - self.m[i])\n",
        "            self.v[i] = round(self.beta2 * self.v[i] + (1. - self.beta2) * grads[i]**2, 4)\n",
        "            # self.v[i] += (1. - self.beta2) * (grads[i]**2 - self.v[i])\n",
        "            params[i] = round(params[i] - lr_t * self.m[i] / (np.sqrt(self.v[i] + 1e-7)), 4)"
      ],
      "metadata": {
        "id": "r4VygZO2vEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9kQZYQfq-iT"
      },
      "outputs": [],
      "source": [
        "adam = Adam(lr=0.9)\n",
        "params = np.zeros(2, dtype=np.float32)\n",
        "grads = deriv_f(params)\n",
        "print(f'초기값: params={params}, grads={grads}, func={func(params):.4f}')\n",
        "for i in range(10):\n",
        "    adam.update(params, grads)\n",
        "    print(f'{i+1}회 시행: params={params}, grads={grads}, m={adam.m}, v={adam.v}, func={func(params):.4f}')\n",
        "    grads = deriv_f(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시각화"
      ],
      "metadata": {
        "id": "aFMhdndhvczc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMtY8Nqkq-iT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, y):\n",
        "    #x, y = params[0], params[1]\n",
        "    return x*x / 20.0 + y*y\n",
        "\n",
        "def df(x, y):\n",
        "    #x, y = params[0], params[1]\n",
        "    return np.array((x / 10.0, 2*y))"
      ],
      "metadata": {
        "id": "YneIqEjTwEV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = OrderedDict()\n",
        "optimizers['SGD'] = SGD(lr=0.95)\n",
        "optimizers['Momentum'] = Momentum(lr=0.1)\n",
        "optimizers['AdaGrad'] = AdaGrad(lr=1.5)\n",
        "optimizers['Adam'] = Adam(lr=0.3)"
      ],
      "metadata": {
        "id": "FnApj2TvwJuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "plt.figure(figsize=(10,10))\n",
        "for key in optimizers:\n",
        "    optimizer = optimizers[key]\n",
        "    x_history, y_history = [], []\n",
        "    params = np.array((-7, 2), dtype=np.float32)\n",
        "    for i in range(30):\n",
        "        x_history.append(params[0])\n",
        "        y_history.append(params[1])\n",
        "        grads = df(params[0], params[1])\n",
        "        optimizer.update(params, grads)\n",
        "        \n",
        "    x = np.arange(-10, 10, 0.01)\n",
        "    y = np.arange(-5, 5, 0.01)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = f(X, Y)\n",
        "    \n",
        "    # 외곽선 단순화\n",
        "    mask = Z > 7\n",
        "    Z[mask] = 0\n",
        "    \n",
        "    # 그래프 그리기\n",
        "    plt.subplot(2, 2, idx)\n",
        "    idx += 1\n",
        "    plt.plot(x_history, y_history, 'ro-')\n",
        "    plt.contour(X, Y, Z)\n",
        "    plt.xlim(-10, 10), plt.ylim(-10, 10)\n",
        "    plt.plot(0, 0, '+')\n",
        "    plt.title(key), plt.xlabel('X'), plt.ylabel('Y')\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OHZgLVTjwQwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "5a1baeb1610b05443f415525bf52a486212d0ee94c2d320214bf0d7d56e225dd"
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 ('vsc')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "10.옵티마이저.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}